---
title: |
    | Segunda Lista de Exercícios: 
    | Modelos de Entrada
author: "Guilherme Jardim - 2512502"
output: pdf_document
header-includes:
    - \usepackage{caption}
    - \usepackage{bbm}
fontsize: 12pt    
---

\captionsetup[table]{labelformat=empty}


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
options(knitr.kable.NA = '')
library(tidyverse)
library(kableExtra)

quibble <- function(x, q = c(0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9)) {
  tibble("{{ x }}" := quantile(x, q), "{{ x }}_q" := q)
}
```

```{r, echo = FALSE, message = FALSE}
data <- read_table("data/tiredealers.txt", col_names = FALSE) %>% 
  select(id = X1, n = X2, tpop = X3, ngrw = X4, pgrw = X5, 
         octy = X6, opop = X7, landv = X8, eld = X9, 
         ffrac = X10, pinc = X11, lnhdd = X12)
```

# Questão 1
**(a)** Para investigar as previsões teóricas, vamos montar um gráfico ilustrando a distribuição da população para cada número de empresas na cidade, com um _box plot_.  
```{r, echo = FALSE, message = FALSE}
data %>% 
  mutate(n = ifelse(n >= 5, "5+", n)) %>% 
  ggplot(aes(x = factor(n), y = tpop)) +
  geom_boxplot() + 
  xlab("Número de Revendedores") +
  ylab("População") +
  theme_bw()
```

É possível observar que de fato há um relação positiva entre o número de revendedores e a população na cidade, com a distribuição da população se concentrando em valores maiores conforme aumentamos o número de revendedores. Além disso, é possível observar que realmente há uma maior dispersão na população conforme o número de revendedores aumenta, o que sugere a presença de aumento da variância nos thresholds conforme $n$ aumenta. Entretanto, apenas pelo gráfico não é claro que os thresholds $S_n$ crescem mais que proporcionalmente, vamos tentar investigar isso na tabela abaixo.

```{r, echo = FALSE, message = FALSE}
data %>% 
  mutate(n = ifelse(n >= 5, "5+", n)) %>% 
  group_by(n) %>% 
  summarise(quibble(tpop)) %>% 
  mutate(tpop_q = as.character(tpop_q)) %>% 
  rbind(data %>% mutate(n = ifelse(n >= 5, "5+", n)) %>% 
          group_by(n) %>% 
          summarise(tpop = mean(tpop), tpop_q = "Média")) %>% 
  pivot_wider(id_cols = tpop_q,
              values_from = tpop,
              names_from = n) %>% 
  rename("Percentil" = tpop_q) %>% 
  kbl(caption = "Distribuição da População pelo Número de Revendedores na Cidade",
      booktabs = TRUE, digits = 2) %>%
  kable_styling(latex_options = "HOLD_position")
```

A partir da tabela, vemos que ao sairmos de um revendedor para dois a população aproximadamente dobra para alguns dos quantis mas o aumento não é mais do que proporcional para nenhum deles, sugerindo que não é visível no dado bruto que os thresholds $S_n$ crescem mais do que proporcionalmente de $n=1$ para $n=2$. Quando observamos $n=3$, essa relação é ainda menos clara, com muitos dos quantis de população estando próximos dos condicionais a $n=2$, não dando uma noção clara do que ocorre de $s_2$ para $s_3$. Para $n=4$, já parece haver uma diferença maior em relação aos valores de $n$ menores na distribuição da população, entretanto, o número de cidades com 4 revendedores é bem menor do que das categorias anteriores e as comparações já passam a ser menos convincentes. A tabela abaixo mostra a quantidade de cidades conforme o número de revendedores.

```{r, echo = FALSE, message = FALSE}
data %>% 
  mutate(n = ifelse(n >= 5, "5+", n)) %>% 
  group_by(n) %>% 
  summarise("Número de Cidades" = n()) %>% 
  rename("Revendedores" = n) %>% 
  kbl(caption = "Número de Cidades Observadas pelo Número de Revendedores na Cidade",
      booktabs = TRUE) %>%
  kable_styling(latex_options = "HOLD_position")
```

Para 5 ou mais revendedores, a diferença na distribuição de população é bem clara, mas pode estar sendo gerada pela agregação de números diferentes de revendedores em um mesmo grupo, o que é mostrado no gráfico abaixo. Uma anotação válida é que os grupos com $n \geq 5$ se tornam menos numerosos, o que torna nossas comparações novamente menos convincentes, o que pode argumentar a favor da decisão do artigo original de unificar o grupo com 5 ou mais firmas. 

```{r, echo = FALSE, message = FALSE}
data %>% 
  mutate(n = ifelse(n >= 8, "8+", n)) %>% 
  ggplot(aes(x = factor(n), y = tpop)) +
  geom_boxplot() + 
  xlab("Número de Revendedores") +
  ylab("População") +
  theme_bw()
```

Um ponto relevante a ser levantado é que o $S$ utilizado no modelo não se limita à população. Como os outros preditores utilizados em Bresnahan and Reiss (1991) não estão sendo levados em conta, não é tão direto afirmar que os $s_n$ não crescem com $n$.

**(b)** Para isso, precisamos montar a função de verossimilhança a ser maximizada. A função de lucro da firma em um mercado com $N$ firmas é dada por:
$$
\Pi_{N}=S(\mathbf{Y}, \lambda) V_{N}(\mathbf{Z}, \mathbf{W}, \alpha, \beta)-F_{N}(\mathbf{W}, \gamma)+\epsilon
$$

Onde $\epsilon$ tem distribuição normal e é independente entre mercados e das variáveis observáveis.
$$
\begin{aligned}
S(\mathbf{Y}, \lambda)=& \text { town population }+\lambda_{1} \text { nearby population } \\
&+\lambda_{2} \text { positive growth }+\lambda_{3} \text { negative growth } \\
&+\lambda_{4} \text { commuters out of the county. }
\end{aligned}
$$

$$
V_{N}=\alpha_{1}+\mathbf{X} \beta-\sum_{n=2}^{N} \alpha_{n}
$$

$$
F_{N}=\gamma_{1}+\gamma_{L} W_{L}+\sum_{n=2}^{N} \gamma_{n}
$$

A probabilidade de observar mercados sem firmas é dada por:
$$
\operatorname{Pr}\left(\Pi_{1}<0\right)=1-\Phi\left(\bar{\Pi}_{1}\right)
$$

A probabilidade de observar mercados com $N$ entre 2 e 4 firmas é dada por:
$$
\operatorname{Pr}\left(\Pi_{N} \geq 0 \text { e } \Pi_{N+1}<0\right)=\Phi\left(\bar{\Pi}_{N}\right)-\Phi\left(\bar{\Pi}_{N+1}\right)
$$

E a probabilidade residual de observar mercados com 5 ou mais firmas é:
$$
\operatorname{Pr}\left(\Pi_{5} \geq 0\right)=\Phi\left(\bar{\Pi}_{5}\right)
$$

Esse modelo é análogo ao Probit Ordenado, então basta maximizar a verossimilhança dele. Os resultados da replicação são mostrados na tabela abaixo.

```{r, echo = FALSE, message = FALSE, warning = FALSE}
df <- data %>% 
  mutate(n = ifelse(n >= 5, 5, n))

likelihood <- function(params, .data) {
  
  # parameters to be chosen
  lambda1 <- params[1]
  lambda2 <- params[2]
  lambda3 <- params[3]
  lambda4 <- params[4]
  
  alpha1 <- params[5]
  alpha2 <- params[6]
  alpha3 <- params[7]
  alpha4 <- 0
  alpha5 <- params[8]
  
  beta2 <- params[9]
  beta3 <- params[10]
  beta4 <- params[11]
  beta7 <- params[12]
  
  gamma1 <- params[13]
  gamma2 <- params[14]
  gamma3 <- params[15]
  gamma4 <- params[16]
  gamma5 <- params[17]
  gammaL <- params[18]
  
  # market size
  S <- .data$tpop + lambda1*.data$opop + lambda2*.data$ngrw + lambda3*.data$pgrw + lambda4*.data$octy
  
  # defining independent variables
  XBeta <- beta2*.data$eld + beta3*.data$pinc + beta4*.data$lnhdd + beta7*.data$ffrac
  W <- .data$landv
  
  # building profit function
  Pi_bar1 <- S * (alpha1 + XBeta) - (gamma1 + gammaL*W)
  
  Pi_bar2 <- S * (alpha1 + XBeta - alpha2) - (gamma1 + gammaL*W + gamma2)
  
  Pi_bar3 <- S * (alpha1 + XBeta - alpha2 - alpha3) - (gamma1 + gammaL*W + gamma2 + gamma3)
  
  Pi_bar4 <- S * (alpha1 + XBeta - alpha2 - alpha3 - alpha4) - (gamma1 + gammaL*W + gamma2 + gamma3 + gamma4)
  
  Pi_bar5 <- S * (alpha1 + XBeta - alpha2 - alpha3 - alpha4 - alpha5) - (gamma1 + gammaL*W + gamma2 + gamma3 + gamma4 + gamma5)
  
  
  # building likelihood function
  ml <- rep(0, nrow(.data))
  N <- .data$n
  
  ml[N == 0] <- 1 - pnorm(Pi_bar1[N == 0], mean = 0, sd = 1)
  ml[N == 1] <- pnorm(Pi_bar1[N == 1], mean = 0, sd = 1) - pnorm(Pi_bar2[N == 1], mean = 0, sd = 1)
  ml[N == 2] <- pnorm(Pi_bar2[N == 2], mean = 0, sd = 1) - pnorm(Pi_bar3[N == 2], mean = 0, sd = 1)
  ml[N == 3] <- pnorm(Pi_bar3[N == 3], mean = 0, sd = 1) - pnorm(Pi_bar4[N == 3], mean = 0, sd = 1)
  ml[N == 4] <- pnorm(Pi_bar4[N == 4], mean = 0, sd = 1) - pnorm(Pi_bar5[N == 4], mean = 0, sd = 1)
  ml[N == 5] <- pnorm(Pi_bar5[N == 5], mean = 0, sd = 1)
  
  l = sum(log(ml))
  
  return(-l)
  
}

initial_pars <- c(-0.5, 2, 0.1, 0.1, 
                  0.8, 0.01, 0.15, 0.08,
                  -0.5, -0.01, 0.01, -0.02,
                  0.5, 0.8, 0.4, 0.6, 0.3, -0.7)

sol <- optim(initial_pars, likelihood, .data = df, method = "BFGS", hessian = TRUE)
se <- sqrt(diag(solve(sol$hessian)))
```

```{r, echo = FALSE, message = FALSE, warning = FALSE}
res <- cbind(sol$par, se)
results <- res[1:4, ] %>% # lambdas
  rbind(res[9:12, ]) %>%  # betas
  rbind(res[5:7, ]) %>%   # alpha 1:3
  rbind(c(NA, NA)) %>%    # alpha 4
  rbind(res[8, ]) %>%     # alpha 5
  rbind(res[13:18, ])     # gammas

colnames(results) <- c("Estimativa", "Erro-padrão assintótico")
rownames(results) <- c("$\\lambda_1$", "$\\lambda_2$", "$\\lambda_3$", "$\\lambda_4$",
                        "$\\beta_2$", "$\\beta_3$", "$\\beta_4$", "$\\beta_7$",
                        "$\\alpha_1$", "$\\alpha_2$", "$\\alpha_3$", "$\\alpha_4$", "$\\alpha_5$",
                        "$\\gamma_1$", "$\\gamma_2$", "$\\gamma_3$", "$\\gamma_4$", "$\\gamma_5$", "$\\gamma_L$")


# add likelihood
l <- data.frame(Estimativa = -sol$value, `Erro-padrão assintótico` = NA, 
                row.names = "Log likelihood", check.names = FALSE)

results %>% 
  rbind(l) %>% 
  kbl(caption = "Tabela 4 - Bresnahan and Reiss (1991)",
      booktabs = TRUE, digits = 2, escape = FALSE, linesep = "") %>%
  kable_styling(latex_options = "HOLD_position")
```

Os erros-padrão não estão exatamente iguais mas, como a estimação depende de métodos numéricos, é esperado que haja uma diferença. Ainda assim, os parâmetros estimados estão iguais aos apresentados por Bresnahan and Reiss (1991).


**(c)** Estimando novamente sem a restrição de $\alpha_4 = 0$ como no artigo original, temos o resultado na tabela abaixo.

```{r, echo = FALSE, message = FALSE, warning = FALSE}
df <- data %>% 
  mutate(n = ifelse(n >= 5, 5, n))

likelihood <- function(params, .data) {
  
  # parameters to be chosen
  lambda1 <- params[1]
  lambda2 <- params[2]
  lambda3 <- params[3]
  lambda4 <- params[4]
  
  alpha1 <- params[5]
  alpha2 <- params[6]
  alpha3 <- params[7]
  alpha4 <- params[8]
  alpha5 <- params[9]
  
  beta2 <- params[10]
  beta3 <- params[11]
  beta4 <- params[12]
  beta7 <- params[13]
  
  gamma1 <- params[14]
  gamma2 <- params[15]
  gamma3 <- params[16]
  gamma4 <- params[17]
  gamma5 <- params[18]
  gammaL <- params[19]
  
  # market size
  S <- .data$tpop + lambda1*.data$opop + lambda2*.data$ngrw + lambda3*.data$pgrw + lambda4*.data$octy
  
  # defining independent variables
  XBeta <- beta2*.data$eld + beta3*.data$pinc + beta4*.data$lnhdd + beta7*.data$ffrac
  W <- .data$landv
  
  # building profit function
  Pi_bar1 <- S * (alpha1 + XBeta) - (gamma1 + gammaL*W)
  
  Pi_bar2 <- S * (alpha1 + XBeta - alpha2) - (gamma1 + gammaL*W + gamma2)
  
  Pi_bar3 <- S * (alpha1 + XBeta - alpha2 - alpha3) - (gamma1 + gammaL*W + gamma2 + gamma3)
  
  Pi_bar4 <- S * (alpha1 + XBeta - alpha2 - alpha3 - alpha4) - (gamma1 + gammaL*W + gamma2 + gamma3 + gamma4)
  
  Pi_bar5 <- S * (alpha1 + XBeta - alpha2 - alpha3 - alpha4 - alpha5) - (gamma1 + gammaL*W + gamma2 + gamma3 + gamma4 + gamma5)
  
  
  # building likelihood function
  ml <- rep(0, nrow(.data))
  N <- .data$n
  
  ml[N == 0] <- 1 - pnorm(Pi_bar1[N == 0], mean = 0, sd = 1)
  ml[N == 1] <- pnorm(Pi_bar1[N == 1], mean = 0, sd = 1) - pnorm(Pi_bar2[N == 1], mean = 0, sd = 1)
  ml[N == 2] <- pnorm(Pi_bar2[N == 2], mean = 0, sd = 1) - pnorm(Pi_bar3[N == 2], mean = 0, sd = 1)
  ml[N == 3] <- pnorm(Pi_bar3[N == 3], mean = 0, sd = 1) - pnorm(Pi_bar4[N == 3], mean = 0, sd = 1)
  ml[N == 4] <- pnorm(Pi_bar4[N == 4], mean = 0, sd = 1) - pnorm(Pi_bar5[N == 4], mean = 0, sd = 1)
  ml[N == 5] <- pnorm(Pi_bar5[N == 5], mean = 0, sd = 1)
  
  l = sum(log(ml))
  
  return(-l)
  
}

initial_pars <- c(-0.5, 2, 0.1, 0.1, 
                  0.8, 0.01, 0.15, 0, 0.08,
                  -0.5, -0.01, 0.01, -0.02,
                  0.5, 0.8, 0.4, 0.6, 0.3, -0.7)

sol <- optim(initial_pars, likelihood, .data = df, method = "BFGS", hessian = TRUE)
se <- sqrt(diag(solve(sol$hessian)))
```

```{r, echo = FALSE, message = FALSE, warning = FALSE}
res <- cbind(sol$par, se)
results <- res[1:4, ] %>% # lambdas
  rbind(res[10:13, ]) %>% # betas
  rbind(res[5:9, ]) %>%   # alpha 1:5
  rbind(res[14:19, ])     # gammas

colnames(results) <- c("Estimativa", "Erro-padrão assintótico")
rownames(results) <- c("$\\lambda_1$", "$\\lambda_2$", "$\\lambda_3$", "$\\lambda_4$",
                        "$\\beta_2$", "$\\beta_3$", "$\\beta_4$", "$\\beta_7$",
                        "$\\alpha_1$", "$\\alpha_2$", "$\\alpha_3$", "$\\alpha_4$", "$\\alpha_5$",
                        "$\\gamma_1$", "$\\gamma_2$", "$\\gamma_3$", "$\\gamma_4$", "$\\gamma_5$", "$\\gamma_L$")


# add likelihood
l <- data.frame(Estimativa = -sol$value, `Erro-padrão assintótico` = NA, 
                row.names = "Log likelihood", check.names = FALSE)

results %>% 
  rbind(l) %>% 
  kbl(caption = "Tabela 4 - Bresnahan and Reiss (1991) com $\\alpha_4$",
      booktabs = TRUE, digits = 2, escape = FALSE, linesep = "") %>%
  kable_styling(latex_options = "HOLD_position")
```

A restrição imposta ao parâmetro $\alpha_4$ não parece ter grandes impactos na estimação dos demais coeficientes e o parâmetro estimado para $\alpha_4$ não é estatisticamente diferente de zero, o que argumenta em favor do artigo original. Economicamente, a restrição faz sentido ao exigir que os lucros em um mercado com 4 firmas sejam menores do que em um mercado com 3. Por outro lado, essa imposição pode ser excessivamente restritiva já que os menores lucros das firmas que entram no mercado depois podem advir de maiores custos conforme o número de firmas aumenta, o que parece ser verdade dado o valor estimado para $\gamma_4$. Além disso, através dessa restrição, os autores tomam como dado uma premissa central do modelo desenvolvido em Bresnahan and Reiss (1990) e Bresnahan and Reiss (1991) que deveria ser refletida pelos dados observados. Diante disso, decisão não parece ser justificada. 

**(d)** Os resultados das estimações introduzindo $-\alpha n$ e $-\alpha \log(n)$ no V ao invés das dummies está exposto nas duas tabelas abaixo. Não há grandes diferenças em relação às estimativas originais quando olhamos para os parâmetros $\lambda$'s, $\beta$'s e $\gamma$'s, em termos qualitativos, apesar das estimativas pontuais variarem bastante. Entretanto, agora temos apenas uma estimativa para $\alpha$, o que implica que o efeito da entrada das firmas no lucro é constante para todo $n$, na primeira especificação, ou dado por $-\alpha \times [\log(n) - \log(n-1)]$, na segunda, gerando um efeito que decresce com $n$. Isso gera estimativas bem diferentes do modelo com dummies, especialmente quando $n$ aumenta, pois impõe uma estrutura mais rígida no efeito de $n$.

```{r, echo = FALSE, message = FALSE, warning = FALSE}
df <- data %>% 
  mutate(n = ifelse(n >= 5, 5, n))

likelihood <- function(params, .data) {
  
  # parameters to be chosen
  lambda1 <- params[1]
  lambda2 <- params[2]
  lambda3 <- params[3]
  lambda4 <- params[4]
  
  alpha <- params[5]

  beta2 <- params[6]
  beta3 <- params[7]
  beta4 <- params[8]
  beta7 <- params[9]
  
  gamma1 <- params[10]
  gamma2 <- params[11]
  gamma3 <- params[12]
  gamma4 <- params[13]
  gamma5 <- params[14]
  gammaL <- params[15]
  
  # market size
  S <- .data$tpop + lambda1*.data$opop + lambda2*.data$ngrw + lambda3*.data$pgrw + lambda4*.data$octy
  
  # defining independent variables
  XBeta <- beta2*.data$eld + beta3*.data$pinc + beta4*.data$lnhdd + beta7*.data$ffrac
  W <- .data$landv

  # building profit function
  Pi_bar1 <- S * (XBeta - alpha*1) - (gamma1 + gammaL*W)
  
  Pi_bar2 <- S * (XBeta - alpha*2) - (gamma1 + gammaL*W + gamma2)
  
  Pi_bar3 <- S * (XBeta - alpha*3) - (gamma1 + gammaL*W + gamma2 + gamma3)
  
  Pi_bar4 <- S * (XBeta - alpha*4) - (gamma1 + gammaL*W + gamma2 + gamma3 + gamma4)
  
  Pi_bar5 <- S * (XBeta - alpha*5) - (gamma1 + gammaL*W + gamma2 + gamma3 + gamma4 + gamma5)
  
  
  # building likelihood function
  ml <- rep(0, nrow(.data))
  N <- .data$n
  
  ml[N == 0] <- 1 - pnorm(Pi_bar1[N == 0], mean = 0, sd = 1)
  ml[N == 1] <- pnorm(Pi_bar1[N == 1], mean = 0, sd = 1) - pnorm(Pi_bar2[N == 1], mean = 0, sd = 1)
  ml[N == 2] <- pnorm(Pi_bar2[N == 2], mean = 0, sd = 1) - pnorm(Pi_bar3[N == 2], mean = 0, sd = 1)
  ml[N == 3] <- pnorm(Pi_bar3[N == 3], mean = 0, sd = 1) - pnorm(Pi_bar4[N == 3], mean = 0, sd = 1)
  ml[N == 4] <- pnorm(Pi_bar4[N == 4], mean = 0, sd = 1) - pnorm(Pi_bar5[N == 4], mean = 0, sd = 1)
  ml[N == 5] <- pnorm(Pi_bar5[N == 5], mean = 0, sd = 1)
  
  l = sum(log(ml))
  
  return(-l)
  
}

initial_pars <- c(-0.5, 0.5, 0.1, 0.1, 
                  0.01,
                  -0.5, -0.01, 0.01, -0.02,
                  0.5, 0.8, 0.4, 0.6, 0.3, -0.7)

sol <- optim(initial_pars, likelihood, .data = df, method = "BFGS", hessian = TRUE)
se <- sqrt(diag(solve(sol$hessian)))
```

```{r, echo = FALSE, message = FALSE, warning = FALSE}
res <- cbind(sol$par, se)
results <- res[1:4, ] %>% # lambdas
  rbind(res[6:9, ]) %>%   # betas
  rbind(res[5, ]) %>%     # alpha
  rbind(res[10:15, ])     # gammas

colnames(results) <- c("Estimativa", "Erro-padrão assintótico")
rownames(results) <- c("$\\lambda_1$", "$\\lambda_2$", "$\\lambda_3$", "$\\lambda_4$",
                        "$\\beta_2$", "$\\beta_3$", "$\\beta_4$", "$\\beta_7$",
                        "$\\alpha$",
                        "$\\gamma_1$", "$\\gamma_2$", "$\\gamma_3$", "$\\gamma_4$", "$\\gamma_5$", "$\\gamma_L$")


# add likelihood
l <- data.frame(Estimativa = -sol$value, `Erro-padrão assintótico` = NA, 
                row.names = "Log likelihood", check.names = FALSE)

results %>% 
  rbind(l) %>% 
  kbl(caption = "Tabela 4 - Bresnahan and Reiss (1991) com $-\\alpha n$ substituindo dummies",
      booktabs = TRUE, digits = 2, escape = FALSE, linesep = "") %>%
  kable_styling(latex_options = "HOLD_position")
```



```{r, echo = FALSE, message = FALSE, warning = FALSE}
df <- data %>% 
  mutate(n = ifelse(n >= 5, 5, n))

likelihood <- function(params, .data) {
  
  # parameters to be chosen
  lambda1 <- params[1]
  lambda2 <- params[2]
  lambda3 <- params[3]
  lambda4 <- params[4]
  
  alpha <- params[5]

  beta2 <- params[6]
  beta3 <- params[7]
  beta4 <- params[8]
  beta7 <- params[9]
  
  gamma1 <- params[10]
  gamma2 <- params[11]
  gamma3 <- params[12]
  gamma4 <- params[13]
  gamma5 <- params[14]
  gammaL <- params[15]
  
  # market size
  S <- .data$tpop + lambda1*.data$opop + lambda2*.data$ngrw + lambda3*.data$pgrw + lambda4*.data$octy
  
  # defining independent variables
  XBeta <- beta2*.data$eld + beta3*.data$pinc + beta4*.data$lnhdd + beta7*.data$ffrac
  W <- .data$landv
  
  # building profit function
  Pi_bar1 <- S * (XBeta - alpha*log(1)) - (gamma1 + gammaL*W)
  
  Pi_bar2 <- S * (XBeta - alpha*log(2)) - (gamma1 + gammaL*W + gamma2)
  
  Pi_bar3 <- S * (XBeta - alpha*log(3)) - (gamma1 + gammaL*W + gamma2 + gamma3)
  
  Pi_bar4 <- S * (XBeta - alpha*log(4)) - (gamma1 + gammaL*W + gamma2 + gamma3 + gamma4)
  
  Pi_bar5 <- S * (XBeta - alpha*log(5)) - (gamma1 + gammaL*W + gamma2 + gamma3 + gamma4 + gamma5)
  
  
  # building likelihood function
  ml <- rep(0, nrow(.data))
  N <- .data$n
  
  ml[N == 0] <- 1 - pnorm(Pi_bar1[N == 0], mean = 0, sd = 1)
  ml[N == 1] <- pnorm(Pi_bar1[N == 1], mean = 0, sd = 1) - pnorm(Pi_bar2[N == 1], mean = 0, sd = 1)
  ml[N == 2] <- pnorm(Pi_bar2[N == 2], mean = 0, sd = 1) - pnorm(Pi_bar3[N == 2], mean = 0, sd = 1)
  ml[N == 3] <- pnorm(Pi_bar3[N == 3], mean = 0, sd = 1) - pnorm(Pi_bar4[N == 3], mean = 0, sd = 1)
  ml[N == 4] <- pnorm(Pi_bar4[N == 4], mean = 0, sd = 1) - pnorm(Pi_bar5[N == 4], mean = 0, sd = 1)
  ml[N == 5] <- pnorm(Pi_bar5[N == 5], mean = 0, sd = 1)
  
  l = sum(log(ml))
  
  return(-l)
  
}

initial_pars <- c(-0.5, 0.5, 0.1, 0.1, 
                  0.01,
                  -0.5, -0.01, 0.01, -0.02,
                  0.5, 0.8, 0.4, 0.6, 0.3, -0.7)

sol <- optim(initial_pars, likelihood, .data = df, method = "BFGS", hessian = TRUE)
se <- sqrt(diag(solve(sol$hessian)))
```

```{r, echo = FALSE, message = FALSE, warning = FALSE}
res <- cbind(sol$par, se)
results <- res[1:4, ] %>% # lambdas
  rbind(res[6:9, ]) %>%   # betas
  rbind(res[5, ]) %>%     # alpha
  rbind(res[10:15, ])     # gammas

colnames(results) <- c("Estimativa", "Erro-padrão assintótico")
rownames(results) <- c("$\\lambda_1$", "$\\lambda_2$", "$\\lambda_3$", "$\\lambda_4$",
                        "$\\beta_2$", "$\\beta_3$", "$\\beta_4$", "$\\beta_7$",
                        "$\\alpha$",
                        "$\\gamma_1$", "$\\gamma_2$", "$\\gamma_3$", "$\\gamma_4$", "$\\gamma_5$", "$\\gamma_L$")


# add likelihood
l <- data.frame(Estimativa = -sol$value, `Erro-padrão assintótico` = NA, 
                row.names = "Log likelihood", check.names = FALSE)

results %>% 
  rbind(l) %>% 
  kbl(caption = "Tabela 4 - Bresnahan and Reiss (1991) com $-\\alpha \\log(n)$ substituindo dummies",
      booktabs = TRUE, digits = 2, escape = FALSE, linesep = "") %>%
  kable_styling(latex_options = "HOLD_position")
```


Os resultados das estimações introduzindo $\gamma n$ e $\gamma \log(n)$ no F ao invés das dummies está exposto nas duas tabelas abaixo. Novamente, não há grandes diferenças em relação às estimativas originais quando olhamos para os parâmetros $\alpha$'s, $\beta$'s e $\lambda$'s, em termos qualitativos, apesar das estimativas pontuais variarem bastante. 

Analogamente aos modelos anteriores, agora temos apenas uma estimativa para $\gamma$, o que implica que o efeito da entrada das firmas no custo fixo é constante para todo $n$, na primeira especificação, ou dado por $\gamma \times [\log(n) - \log(n-1)]$, na segunda, gerando um efeito que decresce com $n$. Isso gera estimativas bem diferentes do modelo com dummies, pois impõe uma estrutura mais rígida no efeito de $n$.

```{r, echo = FALSE, message = FALSE, warning = FALSE}
df <- data %>% 
  mutate(n = ifelse(n >= 5, 5, n))

likelihood <- function(params, .data) {
  
  # parameters to be chosen
  lambda1 <- params[1]
  lambda2 <- params[2]
  lambda3 <- params[3]
  lambda4 <- params[4]
  
  alpha1 <- params[5]
  alpha2 <- params[6]
  alpha3 <- params[7]
  alpha4 <- params[8]
  alpha5 <- params[9]
  
  beta2 <- params[10]
  beta3 <- params[11]
  beta4 <- params[12]
  beta7 <- params[13]
  
  gamma <- params[14]
  gammaL <- params[15]
  
  # market size
  S <- .data$tpop + lambda1*.data$opop + lambda2*.data$ngrw + lambda3*.data$pgrw + lambda4*.data$octy
  
  # defining independent variables
  XBeta <- beta2*.data$eld + beta3*.data$pinc + beta4*.data$lnhdd + beta7*.data$ffrac
  W <- .data$landv
  
  # building profit function
  Pi_bar1 <- S * (alpha1 + XBeta) - (gamma*1 + gammaL*W)
  
  Pi_bar2 <- S * (alpha1 + XBeta - alpha2) - (gamma*2 + gammaL*W)
  
  Pi_bar3 <- S * (alpha1 + XBeta - alpha2 - alpha3) - (gamma*3 + gammaL*W)
  
  Pi_bar4 <- S * (alpha1 + XBeta - alpha2 - alpha3 - alpha4) - (gamma*4 + gammaL*W)
  
  Pi_bar5 <- S * (alpha1 + XBeta - alpha2 - alpha3 - alpha4 - alpha5) - (gamma*5 + gammaL*W)
  
  
  # building likelihood function
  ml <- rep(0, nrow(.data))
  N <- .data$n
  
  ml[N == 0] <- 1 - pnorm(Pi_bar1[N == 0], mean = 0, sd = 1)
  ml[N == 1] <- pnorm(Pi_bar1[N == 1], mean = 0, sd = 1) - pnorm(Pi_bar2[N == 1], mean = 0, sd = 1)
  ml[N == 2] <- pnorm(Pi_bar2[N == 2], mean = 0, sd = 1) - pnorm(Pi_bar3[N == 2], mean = 0, sd = 1)
  ml[N == 3] <- pnorm(Pi_bar3[N == 3], mean = 0, sd = 1) - pnorm(Pi_bar4[N == 3], mean = 0, sd = 1)
  ml[N == 4] <- pnorm(Pi_bar4[N == 4], mean = 0, sd = 1) - pnorm(Pi_bar5[N == 4], mean = 0, sd = 1)
  ml[N == 5] <- pnorm(Pi_bar5[N == 5], mean = 0, sd = 1)
  
  l = sum(log(ml))
  
  return(-l)
  
}

initial_pars <- c(-0.5, 2, 0.1, 0.1, 
                  0.5, 0.01, 0.15, 0, 0.08,
                  -0.5, -0.01, 0.01, -0.02,
                  0.05, -0.5)

sol <- optim(initial_pars, likelihood, .data = df, method = "BFGS", hessian = TRUE)
se <- sqrt(diag(solve(sol$hessian)))
```

```{r, echo = FALSE, message = FALSE, warning = FALSE}
res <- cbind(sol$par, se)
results <- res[1:4, ] %>% # lambdas
  rbind(res[10:13, ]) %>% # betas
  rbind(res[5:9, ]) %>%   # alpha 1:5
  rbind(res[14:15, ])     # gammas

colnames(results) <- c("Estimativa", "Erro-padrão assintótico")
rownames(results) <- c("$\\lambda_1$", "$\\lambda_2$", "$\\lambda_3$", "$\\lambda_4$",
                        "$\\beta_2$", "$\\beta_3$", "$\\beta_4$", "$\\beta_7$",
                        "$\\alpha_1$", "$\\alpha_2$", "$\\alpha_3$", "$\\alpha_4$", "$\\alpha_5$",
                        "$\\gamma$", "$\\gamma_L$")


# add likelihood
l <- data.frame(Estimativa = -sol$value, `Erro-padrão assintótico` = NA, 
                row.names = "Log likelihood", check.names = FALSE)

results %>% 
  rbind(l) %>% 
  kbl(caption = "Tabela 4 - Bresnahan and Reiss (1991) com $\\gamma n$ substituindo dummies",
      booktabs = TRUE, digits = 2, escape = FALSE, linesep = "") %>%
  kable_styling(latex_options = "HOLD_position")
```


```{r, echo = FALSE, message = FALSE, warning = FALSE}
df <- data %>% 
  mutate(n = ifelse(n >= 5, 5, n))

likelihood <- function(params, .data) {
  
  # parameters to be chosen
  lambda1 <- params[1]
  lambda2 <- params[2]
  lambda3 <- params[3]
  lambda4 <- params[4]
  
  alpha1 <- params[5]
  alpha2 <- params[6]
  alpha3 <- params[7]
  alpha4 <- params[8]
  alpha5 <- params[9]
  
  beta2 <- params[10]
  beta3 <- params[11]
  beta4 <- params[12]
  beta7 <- params[13]
  
  gamma <- params[14]
  gammaL <- params[15]
  
  # market size
  S <- .data$tpop + lambda1*.data$opop + lambda2*.data$ngrw + lambda3*.data$pgrw + lambda4*.data$octy
  
  # defining independent variables
  XBeta <- beta2*.data$eld + beta3*.data$pinc + beta4*.data$lnhdd + beta7*.data$ffrac
  W <- .data$landv
  
  # building profit function
  Pi_bar1 <- S * (alpha1 + XBeta) - (gamma*log(1) + gammaL*W)
  
  Pi_bar2 <- S * (alpha1 + XBeta - alpha2) - (gamma*log(2) + gammaL*W)
  
  Pi_bar3 <- S * (alpha1 + XBeta - alpha2 - alpha3) - (gamma*log(3) + gammaL*W)
  
  Pi_bar4 <- S * (alpha1 + XBeta - alpha2 - alpha3 - alpha4) - (gamma*log(4) + gammaL*W)
  
  Pi_bar5 <- S * (alpha1 + XBeta - alpha2 - alpha3 - alpha4 - alpha5) - (gamma*log(5) + gammaL*W)
  
  
  # building likelihood function
  ml <- rep(0, nrow(.data))
  N <- .data$n
  
  ml[N == 0] <- 1 - pnorm(Pi_bar1[N == 0], mean = 0, sd = 1)
  ml[N == 1] <- pnorm(Pi_bar1[N == 1], mean = 0, sd = 1) - pnorm(Pi_bar2[N == 1], mean = 0, sd = 1)
  ml[N == 2] <- pnorm(Pi_bar2[N == 2], mean = 0, sd = 1) - pnorm(Pi_bar3[N == 2], mean = 0, sd = 1)
  ml[N == 3] <- pnorm(Pi_bar3[N == 3], mean = 0, sd = 1) - pnorm(Pi_bar4[N == 3], mean = 0, sd = 1)
  ml[N == 4] <- pnorm(Pi_bar4[N == 4], mean = 0, sd = 1) - pnorm(Pi_bar5[N == 4], mean = 0, sd = 1)
  ml[N == 5] <- pnorm(Pi_bar5[N == 5], mean = 0, sd = 1)
  
  l = sum(log(ml))
  
  return(-l)
  
}

initial_pars <- c(-0.5, 1, 0.1, 0.1, 
                  0.5, 0.01, 0.15, 0, 0.08,
                  -0.5, -0.01, 0.01, -0.02,
                  0.05, -0.5)

sol <- optim(initial_pars, likelihood, .data = df, method = "BFGS", hessian = TRUE)
se <- sqrt(diag(solve(sol$hessian)))
```

```{r, echo = FALSE, message = FALSE, warning = FALSE}
res <- cbind(sol$par, se)
results <- res[1:4, ] %>% # lambdas
  rbind(res[10:13, ]) %>% # betas
  rbind(res[5:9, ]) %>%   # alpha 1:5
  rbind(res[14:15, ])     # gammas

colnames(results) <- c("Estimativa", "Erro-padrão assintótico")
rownames(results) <- c("$\\lambda_1$", "$\\lambda_2$", "$\\lambda_3$", "$\\lambda_4$",
                        "$\\beta_2$", "$\\beta_3$", "$\\beta_4$", "$\\beta_7$",
                        "$\\alpha_1$", "$\\alpha_2$", "$\\alpha_3$", "$\\alpha_4$", "$\\alpha_5$",
                        "$\\gamma$", "$\\gamma_L$")


# add likelihood
l <- data.frame(Estimativa = -sol$value, `Erro-padrão assintótico` = NA, 
                row.names = "Log likelihood", check.names = FALSE)

results %>% 
  rbind(l) %>% 
  kbl(caption = "Tabela 4 - Bresnahan and Reiss (1991) com $\\gamma \\log(n)$ substituindo dummies",
      booktabs = TRUE, digits = 2, escape = FALSE, linesep = "") %>%
  kable_styling(latex_options = "HOLD_position")
```



# Questão 2
**(a)** Dada uma realização de $\epsilon$, podemos mostrar que o vetor de decisões de entrada de equilíbrio é único. Sabemos que uma firma entra na localidade $m$ se $\Pi_m > 0$ ou, de forma equivalente, $\epsilon_m > -X_m\beta - \alpha I_{m-1}$

Assim, se tomamos $m=1$, temos que uma usina entra em $1$ se: 
$$
\Pi_1 > 0 \Rightarrow \epsilon_1 > -X_1 \beta
$$

Como as firmas observam todo o vetor $\epsilon$, em $m=2$ a usina sabe se $I_{1} = 1$ ou não. Logo, a usina entra em $2$ se:
$$
\epsilon_2 > -X_2 \beta - \alpha\mathbbm{1}\{\epsilon_1 > -X_1 \beta\}
$$

Assim, podemos resolver esse problema de forma sequencial, computando a escolha em $m=1$, depois usar $I_1$ para computar a escolha em $m=2$ e assim por diante para todas as $M$ localidades, o que mostra que o vetor de decisões de entrada de equilíbrio é único já que a decisão depende apenas da realização do próprio $\epsilon$ após a escolha de $m-1$ e essa escolha não é afetada pela decisão em $m$. Nesse caso, o sinal de $\alpha$ pode alterar o vetor de decisões de entrada, pois um $\alpha$ negativo pode reduzir a probabilidade de se instalar na localidade, ao contrário do $\alpha$ positivo, mas não afeta a unicidade do equilíbrio.

Sabendo a distribuição de $\epsilon$, podemos estimar esse equilíbrio de forma sequencial. Seja $P_m$ a probabilidade de entrada em $m$, podemos então construir a verossimilhança com base nas probabilidades:
$$
P_1 = P(\epsilon_1 > -X_1 \beta) = 1 - F(-X_1 \beta)
$$
\begin{align*}
    P_2 &= P(\epsilon_2 > -X_2 \beta - \alpha I_1) \\        
  &= 1 - F(-X_2 \beta - \alpha I_1)
\end{align*}
$$
\vdots
$$
\begin{align*}
    P_M &= P(\epsilon_M > -X_M \beta - \alpha I_{M-1}) \\        
  &= 1 - F(-X_M \beta - \alpha I_{M-1})
\end{align*}

onde $\epsilon \sim F$.

Como os $I_m$ são variáveis binárias, a maximização da verossimilhança toma a forma:
$$
\max \prod_{m=1}^{M} P_{m}^{I_{m}}\left(1-P_{m}\right)^{1-I_{m}}
$$

**(b)** Agora que cada firma observa apenas o $\epsilon_m$ de sua localidade, a usina entra em $m$ se:
$$
\mathbb{E}[\Pi_m] > 0 \Rightarrow \epsilon_m > -X_m \beta - \alpha P_{m-1}
$$
já que $I_{m-1}$ é binária.

Podemos então construir a verossimilhança com base nas probabilidades:
$$
P_1 = P(\epsilon_1 > -X_1 \beta) = 1 - F(-X_1 \beta)
$$
\begin{align*}
    P_2 &= P(\epsilon_2 > -X_2 \beta - \alpha P_1) \\        
  &= 1 - F(-X_2 \beta - \alpha P_1)
\end{align*}
$$
\vdots
$$
\begin{align*}
    P_M &= P(\epsilon_M > -X_M \beta - \alpha P_{M-1}) \\        
  &= 1 - F(-X_M \beta - \alpha P_{M-1})
\end{align*}

Assim, o equilíbrio ainda é único, podendo novamente ser resolvido de forma sequencial como no item (a). Como os $I_m$ são variáveis binárias, a maximização da verossimilhança toma a forma:
$$
\max \prod_{m=1}^{M} P_{m}^{I_{m}}\left(1-P_{m}\right)^{1-I_{m}}
$$


**(c)** Nessa versão, o $I$ de equilíbrio não é mais único. Podemos ilustrar os casos possíveis para $M=2$.

Quando $\gamma > 0$ e $\alpha > 0$, múltiplos equilíbrios aparecem no cenário onde $-X_1 \beta - \gamma < \epsilon_1 < -X_1 \beta$ e $-X_2 \beta - \alpha < \epsilon_2 < -X_2 \beta$. Nesse caso, temos dois possíveis equilíbrios: (1, 1) e (0, 0).

Quando $\gamma < 0$ e $\alpha < 0$, múltiplos equilíbrios aparecem no cenário onde $-X_1 \beta - \gamma > \epsilon_1 > -X_1 \beta$ e $-X_2 \beta - \alpha > \epsilon_2 > -X_2 \beta$. Nesse caso, temos dois possíveis equilíbrios: (1, 0) e (0, 1).

Os casos onde $\gamma > 0$ e $\alpha < 0$ ou $\gamma < 0$ e $\alpha > 0$ são análogos e não há equilíbrio em estratégias puras no caso onde temos $\epsilon_1$ e $\epsilon_2$ na zona intermediária entre $[-X_1 \beta - \gamma, -X_1 \beta]$ e $[-X_2 \beta - \alpha, -X_2 \beta]$.

Nesse caso, não podemos estimar a verossimilhança como nos casos anteriores devido à multiplicidade de equilíbrios. A solução é ou selecionar arbitrariamente um dos equilíbrios que surgem ou modelar o jogo como não-simultâneo ou definir uma verossimilhança composta. A opção de jogo não-simultâneo pode fazer sentido caso uma das usinas envolvidas no equilíbrio múltiplo seja mais antiga do que a outra e já esteja estabelecida, o que sugere uma ordem para as ações dos jogadores.


# Questão 3
**(a)** Como só temos dados para um período, precisamos interpretar os dados disponíveis da mesma forma que Bresnahan and Reiss (1991), de que os mercados observados são um equilíbrio de longo prazo. Vamos estudar a verossimilhança para entender o que é possível de ser estimado. A probabilidade de observar mercados sem firmas em $i$ é dada por:
\begin{align*}
    P(0 \text{ firmas}) &= P(\Pi_i(n=1) < 0)  \\        
  &= P(X_i\beta + h(1) - \Delta + \epsilon_i < 0) \\
  &= 1 - F(\Delta - h(1) - X_i\beta)
\end{align*}

onde $\epsilon \sim F$.

A probabilidade de observar mercados com $k$ firmas em $i$, com $k$ entre 1 e $N-1$ é dada por:
\begin{align*}
    P(k \text{ firmas}) &= P(\Pi_i(n=k) \geq -\Sigma \text{ e } \Pi_i(n=k+1) < 0) \\        
  &= F(-\Sigma - h(k) - X_i\beta) - F(\Delta - h(k+1) - X_i\beta)
\end{align*}

Por fim, a probabilidade de observar mercados com $N$ firmas em $i$ é:
\begin{align*}
    P(N \text{ firmas}) &= P(\Pi_i(n=N) \geq -\Sigma) \\        
  &= F(-\Sigma - h(N) - X_i\beta)
\end{align*}

Como as funções $h$ sempre aparecem no "intercepto" conjuntamente com $\Delta$ ou $\Sigma$, não é possível estimar os parâmetros separadamente. Isso ocorre pois existem infinitas combinações possíveis para essas somas. Por exemplo, podemos ter um maior valor de $\Delta$ sem alteração no valor dos interceptos se modificarmos também as estimativas de $h$ e $-\Sigma$, não sendo possível identificá-los unicamente.

**(b)** Dada a limitação da base de dados, não levaremos em conta a identidade das firmas presentes no mercado. O que importa será apenas a variação do número de firmas de um período para o outro. Observando o caso de dois períodos, temos 3 casos possíveis:  

* $n_2 > n_1$: a entrada de firmas ocorre quando a $n_2$-ésima entrante tem lucros não negativos e a entrante seguinte tem lucros negativos.
$$
X_{i2}\beta + h(n_2) + \epsilon_{i2} \geq \Delta
$$
$$
X_{i2}\beta + h(n_2 + 1) + \epsilon_{i2} < \Delta
$$

* $n_2 < n_1$: a saída de firmas ocorre quando não é mais lucrativo para $n_1 - n_2$ incumbentes continuarem no mercado.
$$
X_{i2}\beta + h(n_2) + \epsilon_{i2} \geq -\Sigma
$$
$$
X_{i2}\beta + h(n_2 + 1) + \epsilon_{i2} < -\Sigma
$$

* $n_2 = n_1$: o número de firmas não se altera quando não é lucrativa a entrada de uma nova firma mas a permanência das incumbentes é.
$$
X_{i2}\beta + h(n_2) + \epsilon_{i2} \geq -\Sigma
$$
$$
X_{i2}\beta + h(n_2 + 1) + \epsilon_{i2} < \Delta
$$

Assim, podemos definir as probabilidades de observar um mercado com $k$ firmas em $t=1$ e $n$ firmas em $t=2$:
$$
P(n_2 = n, n_1 = k)=\left\{\begin{array}{cc}
F(\Delta - h(n + 1) - X_{i2}\beta) - F(\Delta - h(n) - X_{i2}\beta) & n > k \\
F(\Delta - h(n + 1) - X_{i2}\beta) - F(-\Sigma - h(n) - X_{i2}\beta) & n = k \\
F(-\Sigma - h(n + 1) - X_{i2}\beta) - F(-\Sigma - h(n) - X_{i2}\beta) & n < k
\end{array}\right.
$$

Novamente, não é possível estimar os parâmetros separadamente. Isso ocorre pois existem infinitas combinações possíveis para essas somas. Por exemplo, podemos ter um maior valor de $\Delta$ sem alteração no valor dos interceptos se modificarmos também as estimativas de $h$ e $-\Sigma$, não sendo possível identificá-los unicamente. 

**(c)** Se as firmas são forward-looking, o lucro esperado descontado da firma que entra na localidade $i$ em $t=\tau$ e sai em $T$ é dado por:
$$
E\left[\sum_{t=\tau}^{T-1} \delta^{t-\tau}[X_{it}\beta + h(n_t) + \epsilon_{it}] - \Delta - \delta^{T}\Sigma \right]
$$
onde $\delta$ é um fator de desconto.

Assim, a firma entra se o lucro esperado descontado dela é maior ou igual a zero. Isso ocorre porque existem várias potenciais entrantes, o que não permite que a firma atrase sua decisão de entrada para conseguir lucros maiores no futuro, já que outras firmas entrarão em seu lugar.

Observando mais especificamente o caso de dois períodos, temos novamente 3 casos possíveis: 

* $n_2 > n_1$: a entrada de firmas ocorre quando a $n_2$-ésima entrante tem lucros não negativos e a entrante seguinte tem lucros negativos.
$$
X_{i2}\beta + h(n_2) + \epsilon_{i2} + E\left[\sum_{t=3}^{T-1} \delta^{t-\tau}[X_{it}\beta + h(n_t) + \epsilon_{it}] \right] \geq \Delta
$$
$$
X_{i2}\beta + h(n_2+1) + \epsilon_{i2} + E\left[\sum_{t=3}^{T-1} \delta^{t-\tau}[X_{it}\beta + h(n_t) + \epsilon_{it}] \right] < \Delta
$$

* $n_2 < n_1$: a saída de firmas ocorre quando não é mais lucrativo para $n_1 - n_2$ incumbentes continuarem no mercado.
$$
X_{i2}\beta + h(n_2) + \epsilon_{i2} + E\left[\sum_{t=3}^{T-1} \delta^{t-\tau}[X_{it}\beta + h(n_t) + \epsilon_{it}] \right] \geq -\Sigma
$$
$$
X_{i2}\beta + h(n_2+1) + \epsilon_{i2} + E\left[\sum_{t=3}^{T-1} \delta^{t-\tau}[X_{it}\beta + h(n_t) + \epsilon_{it}] \right] < -\Sigma
$$

* $n_2 = n_1$: o número de firmas não se altera quando não é lucrativa a entrada de uma nova firma mas a permanência das incumbentes é.
$$
X_{i2}\beta + h(n_2) + \epsilon_{i2} + E\left[\sum_{t=3}^{T-1} \delta^{t-\tau}[X_{it}\beta + h(n_t) + \epsilon_{it}] \right] \geq -\Sigma
$$
$$
X_{i2}\beta + h(n_2+1) + \epsilon_{i2} + E\left[\sum_{t=3}^{T-1} \delta^{t-\tau}[X_{it}\beta + h(n_t) + \epsilon_{it}] \right] < \Delta
$$

Tendo apenas dois períodos disponíveis, não é possível estimar algo nesse sentido. Em Bresnahan and Reiss (1994), os autores utilizam o lucro de um período seguinte ($t=3$) para representar todo o fluxo futuro de lucros, entretanto, aqui temos apenas dois períodos.

Se fizermos a suposição de que o lucro em $t=2$ representa todo o fluxo futuro cairíamos no mesmo problema do item anterior. Novamente, não é possível estimar os parâmetros $\Delta$, $h$ e $-\Sigma$ separadamente.

\vspace{1cm}  

# Referências
- Bresnahan, T. F., & Reiss, P. C. (1990). Entry in monopoly market. The Review of Economic Studies, 57(4), 531-553.
- Bresnahan, T. F., & Reiss, P. C. (1991). Entry and competition in concentrated markets. Journal of Political Economy, 99(5), 977-1009.
- Bresnahan, T. F., & Reiss, P. C. (1994). Measuring the importance of sunk costs. Annales d'Economie et de Statistique, 181-217.

